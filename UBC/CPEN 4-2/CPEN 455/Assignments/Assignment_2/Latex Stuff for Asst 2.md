#### Question 1

##### (2)
$$\begin{aligned}

&W_{1} = \begin{bmatrix}
1 & -1 \\
1 & 1
\end{bmatrix} \quad b_{1} = \begin{bmatrix}
0 \\
0
\end{bmatrix} \\ 
&W_{2} = \begin{bmatrix}
1 & 0
\end{bmatrix} \quad b_{2} = 0
\end{aligned}$$

$$\begin{aligned}
\mathbf{x}= \begin{bmatrix}
0 \\
1
\end{bmatrix} &\to \sigma(\begin{bmatrix}
1 & -1  \\
1 & 1
\end{bmatrix}\begin{bmatrix}
0 \\
1
\end{bmatrix} + \begin{bmatrix}
0 \\
0
\end{bmatrix}) \\
&= \sigma(\begin{bmatrix}
-1  \\
1
\end{bmatrix}) = \begin{bmatrix}
1 \\
1
\end{bmatrix} \\ 
&\to \begin{bmatrix}
1 & 0
\end{bmatrix}\begin{bmatrix}
1 \\
1
\end{bmatrix}+0 = 1
\end{aligned}$$
$$\begin{aligned}
\mathbf{x}= \begin{bmatrix}
0 \\
0
\end{bmatrix} &\to \sigma(\begin{bmatrix}
1 & -1  \\
1 & 1
\end{bmatrix}\begin{bmatrix}
0 \\
0
\end{bmatrix} + \begin{bmatrix}
0 \\
0
\end{bmatrix}) \\
&= \sigma(\begin{bmatrix}
0  \\
0
\end{bmatrix}) = \begin{bmatrix}
0 \\
0
\end{bmatrix} \\ 
&\to \begin{bmatrix}
1 & 0
\end{bmatrix}\begin{bmatrix}
0 \\
0
\end{bmatrix}+0 = 0
\end{aligned}$$

$$\begin{aligned}
\mathbf{x}= \begin{bmatrix}
1 \\
0
\end{bmatrix} &\to \sigma(\begin{bmatrix}
1 & -1  \\
1 & 1
\end{bmatrix}\begin{bmatrix}
1 \\
0
\end{bmatrix} + \begin{bmatrix}
0 \\
0
\end{bmatrix}) \\
&= \sigma(\begin{bmatrix}
1  \\
1
\end{bmatrix}) = \begin{bmatrix}
1 \\
1
\end{bmatrix} \\ 
&\to \begin{bmatrix}
1 & 0
\end{bmatrix}\begin{bmatrix}
1 \\
1
\end{bmatrix}+0 = 1
\end{aligned}$$

$$\begin{aligned}
\mathbf{x}= \begin{bmatrix}
0 \\
0
\end{bmatrix} &\to \sigma(\begin{bmatrix}
1 & -1  \\
1 & 1
\end{bmatrix}\begin{bmatrix}
0 \\
0
\end{bmatrix} + \begin{bmatrix}
0 \\
0
\end{bmatrix}) \\
&= \sigma(\begin{bmatrix}
0  \\
0
\end{bmatrix}) = \begin{bmatrix}
0 \\
0
\end{bmatrix} \\ 
&\to \begin{bmatrix}
1 & 0
\end{bmatrix}\begin{bmatrix}
0 \\
0
\end{bmatrix}+0 = 1
\end{aligned}$$

##### (3)
$$\begin{aligned}
&W_{1} = \begin{bmatrix}
1 & -1 \\
-1 & 1
\end{bmatrix} \quad b_{1} = \begin{bmatrix}
0 \\
0
\end{bmatrix} \\ 
&W_{2} = \begin{bmatrix}
1 & 1
\end{bmatrix} \quad b_{2} = \begin{bmatrix}
0 \\
0
\end{bmatrix}
\end{aligned}$$

$$\begin{aligned}
\mathbf{x}= \begin{bmatrix}
0 \\
1
\end{bmatrix} &\to \sigma(\begin{bmatrix}
1 & -1  \\
-1 & 1
\end{bmatrix}\begin{bmatrix}
0 \\
1
\end{bmatrix} + \begin{bmatrix}
0 \\
0
\end{bmatrix}) \\
&= \sigma(\begin{bmatrix}
-1  \\
1
\end{bmatrix}) = \begin{bmatrix}
0 \\
1
\end{bmatrix} \\ 
&\to \begin{bmatrix}
1 & 1
\end{bmatrix}\begin{bmatrix}
0 \\
1
\end{bmatrix}+0 = 1
\end{aligned}$$
$$\begin{aligned}
\mathbf{x}= \begin{bmatrix}
0 \\
0
\end{bmatrix} &\to \sigma(\begin{bmatrix}
1 & -1  \\
-1 & 1
\end{bmatrix}\begin{bmatrix}
0 \\
0
\end{bmatrix} + \begin{bmatrix}
0 \\
0
\end{bmatrix}) \\
&= \sigma(\begin{bmatrix}
0  \\
0
\end{bmatrix}) = \begin{bmatrix}
0 \\
0
\end{bmatrix} \\ 
&\to \begin{bmatrix}
1 & 1
\end{bmatrix}\begin{bmatrix}
0 \\
0
\end{bmatrix}+0 = 0
\end{aligned}$$

$$\begin{aligned}
\mathbf{x}= \begin{bmatrix}
1 \\
0
\end{bmatrix} &\to \sigma(\begin{bmatrix}
1 & -1  \\
-1 & 1
\end{bmatrix}\begin{bmatrix}
1 \\
0
\end{bmatrix} + \begin{bmatrix}
0 \\
0
\end{bmatrix}) \\
&= \sigma(\begin{bmatrix}
1  \\
-1
\end{bmatrix}) = \begin{bmatrix}
1 \\
0
\end{bmatrix} \\ 
&\to \begin{bmatrix}
1 & 1
\end{bmatrix}\begin{bmatrix}
1 \\
0
\end{bmatrix}+0 = 1
\end{aligned}$$
$$\begin{aligned}
\mathbf{x}= \begin{bmatrix}
1 \\
1
\end{bmatrix} &\to \sigma(\begin{bmatrix}
1 & -1  \\
-1 & 1
\end{bmatrix}\begin{bmatrix}
1 \\
1
\end{bmatrix} + \begin{bmatrix}
0 \\
0
\end{bmatrix}) \\
&= \sigma(\begin{bmatrix}
0  \\
0
\end{bmatrix}) = \begin{bmatrix}
0 \\
0
\end{bmatrix} \\ 
&\to \begin{bmatrix}
1 & 1
\end{bmatrix}\begin{bmatrix}
0 \\
0
\end{bmatrix}+0 = 0
\end{aligned}$$

#### Question 2
1st layer:

After padding size
$$\left\lfloor  \frac{512+2 \times 2 -5}{2}  \right\rfloor + 1 = \left\lfloor  \frac{511}{2}  \right\rfloor+1 = 256 $$
After convolution
$$100 \times(128 \times 256 \times 256)$$

2nd layer:

After padding size 
$$\left\lfloor  \frac{256+2\times 2 - 5}{2}  \right\rfloor  + 1 = \left\lfloor  \frac{255}{2}  \right\rfloor +1= 128 $$

After convolution
$$100 \times (64 \times 128 \times 128)$$

3rd layer:

After padding size
$$\left\lfloor   \frac{128 + 1 \times 2 - 3}{2}  \right\rfloor +1 = \left\lfloor  \frac{127}{2}  \right\rfloor +1 = 64$$

After convolution
$$100 \times (32 \times 64 \times 64)$$

4th layer:

After padding size
$$\left\lfloor  \frac{64 + 2 \times 0 - 1}{1}  \right\rfloor +1= \lfloor 63 \rfloor + 1 = 64 $$

After convolution
$$100 \times (16 \times 64 \times 64)$$

5th layer:
$$\left\lfloor  \frac{64 + 2 \times 0 -2 }{2}  \right\rfloor +1 = \left\lfloor  \frac{62}{2}  \right\rfloor +1=32$$

After convolution
$$100 \times (16 \times 32 \times 32)$$

6th layer:
$$100 \times (32\times 32 \times 16) = 100 \times 16384$$
#### 2.1
128, 64, 32

#### 2.2 
Above

#### 2.3
$$\begin{aligned}
128 \times 5 \times 5 \times 3 &+ 64 \times 5 \times 5 \times 128 + 32 \times 3 \times 3 \times 64 + 16 \times 1 \times 1 \times 32 \\ 
&+ 16384 \times 100
\end{aligned}$$

#### 2.4
$$\begin{aligned}
128 \times (5 \times 5 \times 3 +1) &+ 64 \times (5 \times 5 \times 128 + 1) + 32 \times (3 \times 3 \times 64 + 1 \\ 
&+ 16 \times (1 \times 1 \times 32 + 1) + 10 \times (16384 +  1)
\end{aligned}$$

#### 2.5

##### 1
$$\begin{aligned}
&\mu = \frac{1}{B \times C \times H \times W}\sum_{b=1}^B\sum_{c=1}^C\sum_{h=1}^H\sum_{w=1}^W X[b,c,h,w] \\ 
&\sigma = \left( \frac{1}{B \times C \times H \times W}\sum_{b=1}^B\sum_{c=1}^C\sum_{h=1}^H\sum_{w=1}^W (X[b,c,h,w] - \mu)^2\right)^{1/2} \\ 
&\hat{X}[b,c,h,w] = \frac{X[b,c,h,w]- \mu}{\sqrt{ \sigma^2+\epsilon }}
\end{aligned}$$

##### 2
$$\begin{aligned}
&\mu[c] = \frac{1}{B \times H \times W}\sum_{b=1}^B\sum_{h=1}^H\sum_{w=1}^W X[b,c,h,w] \\ 
&\sigma[c] = \left( \frac{1}{B \times H \times W}\sum_{b=1}^B\sum_{h=1}^H\sum_{w=1}^W (X[b,c,h,w] - \mu[c])^2\right)^{1/2} \\ 
&\hat{X}[b,c,h,w] = \frac{X[b,c,h,w]- \mu[c]}{\sqrt{ \sigma[c]^2+\epsilon }}
\end{aligned}$$

##### 3
$$\begin{aligned}
&\mu[h,w] = \frac{1}{B \times C}\sum_{b=1}^B\sum_{c=1}^C X[b,c,h,w] \\ 
&\sigma[h,w] = \left( \frac{1}{B \times C}\sum_{b=1}^B\sum_{c=1}^C (X[b,c,h,w] - \mu[h,w])^2\right)^{1/2} \\ 
&\hat{X}[b,c,h,w] = \frac{X[b,c,h,w]- \mu[h,w]}{\sqrt{ \sigma[h,w]^2+\epsilon }}
\end{aligned}$$

#### 4
$$\begin{aligned}
&\mu[c,h,w] = \frac{1}{B }\sum_{b=1}^B X[b,c,h,w] \\ 
&\sigma[c,h,w] = \left( \frac{1}{B }\sum_{b=1}^B(X[b,c,h,w] - \mu[h,w])^2\right)^{1/2} \\ 
&\hat{X}[b,c,h,w] = \frac{X[b,c,h,w]- \mu[c,h,w]}{\sqrt{ \sigma[c,h,w]^2+\epsilon }}
\end{aligned}$$


### 4
$$
 X' =  \begin{bmatrix}
    0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 
    0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 
    0 & 0 & 3 & 1 & 2 & 6 & 5 & 0 & 0 \\ 
    0 & 0 & 6 & 8 & 1 & 7 & 9 & 0 & 0 \\ 
    0 & 0 & 2 & 7 & 4 & 2 & 3 & 0 & 0 \\ 
    0 & 0 & 8 & 3 & 5 & 4 & 1 & 0 & 0 \\ 
    0 & 0 & 1 & 5 & 2 & 7 & 6 & 0 & 0 \\ 
    0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 
    0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0  
    \end{bmatrix}
    \quad W' = \begin{bmatrix}
-1 & 0 & 2 & 0 & -3  \\
0 & 0 & 0 & 0 & 0 \\
1 & 0 & -2 & 0 & 3 \\
0 & 0 & 0 & 0 & 0 \\
3 & 0 & 2 & 0 & -1
\end{bmatrix}
$$
$$\begin{aligned}
H' &=\left\lfloor   \frac{5 + 2 \times 2 -5 }{2 }  \right\rfloor  + 1 = 3 \\ 
W' &= \left\lfloor   \frac{ 5 + 2 \times 2 -5}{2}  \right\rfloor +1 = 3
\end{aligned}$$

$$\begin{bmatrix}
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 3 & 1 & 2 \\
0 & 0 & 6 & 8 & 1 \\
0 & 0 & 2 & 7 & 4
\end{bmatrix} * \begin{bmatrix}
-1 & 0 & 2 & 0 & -3  \\
0 & 0 & 0 & 0 & 0 \\
1 & 0 & -2 & 0 & 3 \\
0 & 0 & 0 & 0 & 0 \\
3 & 0 & 2 & 0 & -1
\end{bmatrix} = -6 + 6+4-4 = 0$$
$$\begin{bmatrix}
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 \\
3 & 1 & 2 & 6 & 5 \\
6 & 8 & 1 & 7 & 9 \\
2 & 7 & 4 & 2 & 3
\end{bmatrix} * \begin{bmatrix}
-1 & 0 & 2 & 0 & -3  \\
0 & 0 & 0 & 0 & 0 \\
1 & 0 & -2 & 0 & 3 \\
0 & 0 & 0 & 0 & 0 \\
3 & 0 & 2 & 0 & -1
\end{bmatrix} = 3 -4 +15+6+8-3 = 25$$
$$\begin{bmatrix}
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 \\
2 & 6 & 5 & 0 & 0 \\
1 & 7 & 9 & 0 & 0 \\
4 & 2 & 3 & 0 & 0
\end{bmatrix} *  \begin{bmatrix}
-1 & 0 & 2 & 0 & -3  \\
0 & 0 & 0 & 0 & 0 \\
1 & 0 & -2 & 0 & 3 \\
0 & 0 & 0 & 0 & 0 \\
3 & 0 & 2 & 0 & -1
\end{bmatrix} = 2 -10 +12 +6 = 10$$
$$\begin{bmatrix}
0 & 0 & 3 & 1 & 2 \\
0 & 0 & 6 & 8 & 1 \\
0 & 0 & 2 & 7 & 4 \\
0 & 0 & 8 & 3 & 5 \\
0 & 0 & 1 & 5 & 2
\end{bmatrix} * \begin{bmatrix}
-1 & 0 & 2 & 0 & -3  \\
0 & 0 & 0 & 0 & 0 \\
1 & 0 & -2 & 0 & 3 \\
0 & 0 & 0 & 0 & 0 \\
3 & 0 & 2 & 0 & -1
\end{bmatrix} = 6 -6 -4 +12 +2 -2 = 8$$
$$\begin{bmatrix}
3 & 1 & 2 & 6 & 5  \\
6 & 8 & 1 & 7 & 9 \\
2 & 7 & 4 & 2 & 3 \\
8 & 3 & 5 & 4 & 1 \\
1 & 5 & 2 & 7 & 6
\end{bmatrix} *  \begin{bmatrix}
-1 & 0 & 2 & 0 & -3  \\
0 & 0 & 0 & 0 & 0 \\
1 & 0 & -2 & 0 & 3 \\
0 & 0 & 0 & 0 & 0 \\
3 & 0 & 2 & 0 & -1
\end{bmatrix} = -3 +4 -15 +2 -8 +9 +3 +4 -6 = -10$$
$$\begin{bmatrix}
2 & 6 & 5 & 0 & 0 \\
1 & 7 & 9 & 0 & 0 \\
4 & 2 & 3 & 0 & 0 \\
5 & 4 & 1 & 0 & 0 \\
2 & 7 & 6 & 0 & 0
\end{bmatrix} * \begin{bmatrix}
-1 & 0 & 2 & 0 & -3  \\
0 & 0 & 0 & 0 & 0 \\
1 & 0 & -2 & 0 & 3 \\
0 & 0 & 0 & 0 & 0 \\
3 & 0 & 2 & 0 & -1
\end{bmatrix} = -2 + 10 +4 -6 +6 +12 =24$$

$$ X' =  \begin{bmatrix}
    0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 
    0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 
    0 & 0 & 3 & 1 & 2 & 6 & 5 & 0 & 0 \\ 
    0 & 0 & 6 & 8 & 1 & 7 & 9 & 0 & 0 \\ 
    0 & 0 & 2 & 7 & 4 & 2 & 3 & 0 & 0 \\ 
    0 & 0 & 8 & 3 & 5 & 4 & 1 & 0 & 0 \\ 
    0 & 0 & 1 & 5 & 2 & 7 & 6 & 0 & 0 \\ 
    0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 
    0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0  
    \end{bmatrix}
    \quad W' = \begin{bmatrix}
-1 & 0 & 2 & 0 & -3  \\
0 & 0 & 0 & 0 & 0 \\
1 & 0 & -2 & 0 & 3 \\
0 & 0 & 0 & 0 & 0 \\
3 & 0 & 2 & 0 & -1
\end{bmatrix}$$
$$\begin{bmatrix}
0 & 0 & 2 & 7 & 4 \\
0 & 0 & 8 & 3 & 5 \\
0 & 0 & 1 & 5 & 2 \\
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0
\end{bmatrix} * \begin{bmatrix}
-1 & 0 & 2 & 0 & -3  \\
0 & 0 & 0 & 0 & 0 \\
1 & 0 & -2 & 0 & 3 \\
0 & 0 & 0 & 0 & 0 \\
3 & 0 & 2 & 0 & -1
\end{bmatrix} = 4 -12 -2 + 6 = -4$$
$$\begin{bmatrix}
2 & 7 & 4 & 2 & 3 \\
8 & 3 & 5 & 4 & 1 \\
1 & 5 & 2 & 7 & 6  \\
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 
\end{bmatrix} * \begin{bmatrix}
-1 & 0 & 2 & 0 & -3  \\
0 & 0 & 0 & 0 & 0 \\
1 & 0 & -2 & 0 & 3 \\
0 & 0 & 0 & 0 & 0 \\
3 & 0 & 2 & 0 & -1
\end{bmatrix} = -2+8-9+1-4+18 =12$$
$$\begin{bmatrix}
4 & 2 & 3 & 0 & 0 \\
5 & 4 & 1 & 0 & 0 \\
2 & 7 & 6 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0
\end{bmatrix}* \begin{bmatrix}
-1 & 0 & 2 & 0 & -3  \\
0 & 0 & 0 & 0 & 0 \\
1 & 0 & -2 & 0 & 3 \\
0 & 0 & 0 & 0 & 0 \\
3 & 0 & 2 & 0 & -1
\end{bmatrix} = -4 +6 + 2- 12 = -8$$

$$\begin{aligned}
H' &= \left\lfloor  \frac{H+2P-K_{\text{eff}}}{S}  \right\rfloor +1 \\ 
&= \left\lfloor  \frac{H+2P-(K +(K-1) \times (D-1))}{S}  \right\rfloor +1 \\ 
&= \left\lfloor  \frac{H+2P -(K-1) \times D -1}{S}  \right\rfloor  + 1\\
W' &= \left\lfloor  \frac{W+2P-K_{\text{eff}}}{S}  \right\rfloor +1  \\ 
&=\left\lfloor  \frac{W +2P - (K + (K-1) \times(D -1))}{S}  \right\rfloor +1 \\ 
&= \left\lfloor   \frac{ W+2P - (K-1) \times D - 1}{S}  \right\rfloor +1
\end{aligned}$$


$$\begin{aligned}
    H' = \left\lfloor \frac{H + 2P  - (K-1)\times D - 1}{S} \right\rfloor + 1 &\to H' - 1 = \left\lfloor \frac{H + 2P  - (K-1)\times D - 1}{S} \right\rfloor \\ 
                                                              &\to S(H'-1) + P' = H + 2P - (K-1)\times D - 1 \\ 
                                                              &\to H = S(H'-1) -2P + (K-1)\times D + 1 + P' \\ 
  W' = \left\lfloor \frac{W + 2P  - (K-1)\times D - 1}{S} \right\rfloor + 1 &\to W' - 1 = \left\lfloor \frac{W + 2P  - K}{S} \right\rfloor \\ 
                                                              &\to S(W'-1) + P' = W + 2P - K \\ 
                                                              &\to W = S(W'-1) -2P + K + P'
  \end{aligned}$$


#### 3.2
$$Y=\begin{bmatrix}
9 & 8 & 7 \\
6 & 5 & 4 \\
3 & 2 & 1
\end{bmatrix}\quad W= \begin{bmatrix}
-1 & 2 & -3 \\
1 & -2 & 3 \\
3 & 2 & -1
\end{bmatrix}$$
$S=2,P=1,Pâ€™=1$


$$\begin{bmatrix}
-9 & 18 & -27 \\
9 & -18 & 27 \\
27  & 18  & -9
\end{bmatrix}$$
$$\begin{bmatrix}
-8 & 16 & -24 \\
8 & -16 & 24 \\
24 & 16 &  -8
\end{bmatrix}$$
$$\begin{bmatrix}
-7 & 14 & -21 \\
7 & -14 & 21 \\
21  & 14 & -7
\end{bmatrix}$$
$$\begin{bmatrix}
-6 & 12 & -18 \\
6 & -12 & 18 \\
18 & 12 & -6
\end{bmatrix}$$
$$\begin{bmatrix}
-5 & 10 & -15 \\
5 & -10 & 15 \\
15 & 10 & -5
\end{bmatrix}$$
$$\begin{bmatrix}
-4 & 8 & -12 \\
4 & -8 & 12 \\
12 & 8 & -4
\end{bmatrix}$$
$$\begin{bmatrix}
-3 & 6 & -9  \\
3 & -6 & 9 \\
9 & 6 & -3
\end{bmatrix}$$
$$\begin{bmatrix}
-2 & 4 & -6 \\
2 & -4 & 6 \\
6  & 4 & -2
\end{bmatrix}$$
$$\begin{bmatrix}
-1 & 2 & -3 \\
1 & -2 & 3 \\
3 & 2 & -1
\end{bmatrix}$$

$$\begin{bmatrix}
-9 & 18 & -27 -8  & 16 & -24 -7 & 14 & -21 \\ 
9 & -18 & 27 + 8  & -16 & 24+7 & -14 & 21 \\
27-6  & 18+12  & -9 + 24-18-5 & 16 +10 & -8+21-15-4 & 14+8 & -7-12  \\
6 & -12 & 18 +5 & -10 & 15 + 4 & -8 & 12\\
18-3 & 12+6 & -6+15-9-2 & 10+4 & -5 +12-6-1 & 8+2 & -4-3  \\
3 & -6 & 9+2 & -4 & 6+1 & -2 & 3 \\
9 & 6 & -3+6 & 4 & -2+3 & 2 & -1
\end{bmatrix}$$
$$\begin{bmatrix}
-9 & 18 & -35 & 16 & -31 & 14 & -21 \\
9 & -18 & 35 & -16 & 31 & -14 & 21 \\
21 & 30 & -8 & -16 & 31 & -14 & 21 \\
6 & -12 & 23 & -10 & 19 & -8 & 12 \\
15 & 18 & -2 & 14 & 0 & 10 & -7 \\
3 & -6 & 11 & -4 & 7 & -2 & 3 \\
9 & 6 & 3 & 4 & 1 & 2 & -1
\end{bmatrix}$$